{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: NVIDIA GeForce GTX 1650\n",
      "['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Sample Embedding: [-0.04427289  0.00833233  0.02516758 -0.02718833 -0.02465583]\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding  # type: ignore\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Running on GPU:\", torch.cuda.get_device_name(0))\n",
    "    embedding_model_gpu = TextEmbedding(model_name=\"BAAI/bge-small-en-v1.5\", device_ids='0', providers=[\"CUDAExecutionProvider\"])\n",
    "    print(embedding_model_gpu.model.model.get_providers())\n",
    "else:\n",
    "    print(\"Running on CPU\")\n",
    "    print(\"CUDA is not available, FUCK YOU\")\n",
    "    SystemExit()\n",
    "\n",
    "# Test the embedding\n",
    "texts = [\"test sentence\"]\n",
    "embeddings = list(embedding_model_gpu.embed(texts))\n",
    "\n",
    "# Print some sample embeddings\n",
    "print(\"Sample Embedding:\", embeddings[0][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: NVIDIA GeForce GTX 1650\n",
      "Skip loading CUDA and cuDNN DLLs since torch is imported.\n",
      "Providers set for the model: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Sample Embedding: [-0.02156309 -0.09749148  0.02143421 -0.02863909 -0.0390533   0.05127196\n",
      "  0.05042129 -0.03565064  0.05057596  0.01886932 -0.02840709 -0.08733504\n",
      "  0.01903687  0.00870644  0.06403195 -0.02591954 -0.05490663  0.00946044\n",
      " -0.07320883  0.06341328  0.03567642  0.00302083 -0.02848442 -0.06449595\n",
      " -0.04284263  0.02197554  0.03683642 -0.02198843 -0.07166217 -0.05681418\n",
      " -0.0005075   0.0096731   0.03536708 -0.00342844 -0.04049686 -0.04505952\n",
      " -0.01565999 -0.04843641  0.00132272 -0.01311443  0.0588764  -0.02237509\n",
      " -0.04420885 -0.00380544  0.00493966 -0.05098841 -0.00124136  0.04147641\n",
      "  0.09290304 -0.01513154 -0.0607324   0.01232177  0.03985241 -0.01858576\n",
      "  0.03131998  0.04405419  0.0483333   0.00085308  0.06016529  0.03351109\n",
      "  0.06779551  0.08119994 -0.17652608  0.08563371  0.03412975  0.00782999\n",
      " -0.01305643  0.00595144 -0.02423109  0.02817509 -0.02617731 -0.01578888\n",
      " -0.04562663  0.04047108  0.00416633 -0.00461744  0.01545377 -0.06274306\n",
      " -0.00091108 -0.02080265 -0.03147464 -0.01837954 -0.02933509  0.00641866\n",
      " -0.04735374  0.00791377 -0.03044353  0.0469413   0.01906265 -0.00502989\n",
      " -0.0280462  -0.04080619 -0.0207511   0.0347742  -0.01337866 -0.01324977\n",
      "  0.05219996 -0.04539463 -0.02709242  0.25035357 -0.04379641  0.07176528\n",
      " -0.05101418 -0.04420885  0.06831106 -0.03887286 -0.00241183  0.02014532\n",
      " -0.01352043  0.00866133  0.00654755 -0.03954308  0.06269151  0.0149511\n",
      " -0.02951553  0.06248529  0.04529152  0.00404066  0.03098487 -0.0416053\n",
      " -0.0252622  -0.00483977 -0.0798595  -0.02802042  0.04639997 -0.09078927\n",
      "  0.03768708  0.11125681  0.02464354  0.00378611  0.07681772  0.01674265\n",
      " -0.06511462  0.02090576 -0.00383122 -0.00790088 -0.03253153 -0.01928176\n",
      " -0.01623999 -0.04057419 -0.00301922 -0.08769593 -0.01345599 -0.11156614\n",
      "  0.00845511  0.05686573 -0.0476373  -0.0301342  -0.06428973 -0.06862039\n",
      " -0.01438399  0.05294751 -0.02541687 -0.01700043 -0.03250575  0.03217064\n",
      "  0.05856707  0.00770755  0.03108798  0.00710177 -0.04423463 -0.06289773\n",
      " -0.06949683  0.00833911  0.01662665 -0.05970129 -0.02794309 -0.00443055\n",
      " -0.06970306 -0.0326862  -0.005162   -0.02107332 -0.09475904  0.03763553\n",
      "  0.14363366  0.02406354  0.0130951   0.00541655  0.00062189 -0.02554576\n",
      " -0.00175128 -0.04959641 -0.01661376 -0.01644621  0.03340797  0.01239266\n",
      " -0.00449822 -0.04240441  0.02768531  0.01498977 -0.01094266  0.09362482\n",
      " -0.00521033  0.04454397 -0.03322753 -0.07671461 -0.03302131 -0.04905507\n",
      " -0.02799465 -0.03786753  0.0696515  -0.02402487 -0.0446213   0.03660442\n",
      "  0.07733327  0.01316599  0.04562663 -0.01661376  0.06975462 -0.03642397\n",
      " -0.02776265  0.01551821  0.11630925 -0.00167394 -0.00533922 -0.04456975\n",
      "  0.02675731  0.02732442  0.02670576 -0.004814   -0.00884822 -0.00618022\n",
      "  0.00572911 -0.30603355  0.05196796  0.03131998  0.01542799  0.02339332\n",
      " -0.01666532  0.05408174 -0.02133109  0.06624884  0.01401021  0.09089237\n",
      "  0.01605954 -0.02130532  0.05810307  0.0385893  -0.00529411  0.00477211\n",
      "  0.00232     0.06655817  0.03902753  0.00889333  0.00179478  0.00289194\n",
      "  0.00830044  0.00994377  0.00461422  0.19323008  0.15219188  0.03224798\n",
      " -0.04147641  0.03464531  0.01662665  0.01910132 -0.12765145 -0.01285666\n",
      "  0.06526928  0.01714221  0.00658944 -0.02845865 -0.06191818 -0.0175031\n",
      "  0.06784706 -0.02423109 -0.06243373  0.02915465 -0.05619551 -0.04652885\n",
      "  0.00419533 -0.04008441  0.02187243  0.04467285 -0.01728399  0.05078219\n",
      "  0.08099372 -0.01571154 -0.02959287  0.01787687 -0.02077687 -0.01443554\n",
      " -0.00109797 -0.03668175  0.03327909 -0.04106397 -0.05882484 -0.02894842\n",
      "  0.01194799 -0.0448533   0.00126714  0.07300261 -0.05225152 -0.02732442\n",
      " -0.03601153  0.02776265  0.04312619  0.02231065  0.07924083  0.00380866\n",
      "  0.01890799 -0.01205755 -0.03005687 -0.00202355 -0.01411332  0.03910486\n",
      "  0.00312555  0.05454574  0.04397685  0.0253782  -0.01679421  0.02426976\n",
      " -0.00463677 -0.02518487  0.01846976 -0.04714752 -0.01658799 -0.01702621\n",
      " -0.00207672 -0.2887109   0.06099018  0.01404888  0.03307286 -0.05122041\n",
      "  0.02662842  0.03382042 -0.01451288 -0.07021862  0.00402455 -0.03281509\n",
      "  0.0100791  -0.006235    0.05266396 -0.01078799 -0.01372666  0.09073771\n",
      " -0.00976977 -0.02698931 -0.04920974  0.00422755  0.0584124   0.18487808\n",
      " -0.01109088  0.05052441 -0.00077333  0.02155021 -0.01195444  0.08331372\n",
      "  0.0243342   0.02464354 -0.004263    0.07088883 -0.01969421  0.04699285\n",
      " -0.01194155 -0.03320175  0.0469413   0.03446486 -0.0476373  -0.07356972\n",
      "  0.0093251  -0.02130532  0.00876444  0.00975688 -0.03956886  0.01095555\n",
      "  0.00193494 -0.01614976  0.02985064  0.03224798 -0.00666355  0.00717911\n",
      "  0.01510577  0.00807488  0.00081965 -0.02892265 -0.02173065  0.0117611\n",
      " -0.00314972 -0.03124264 -0.04268797  0.07867372  0.0462453  -0.03487731]\n"
     ]
    }
   ],
   "source": [
    "from fastembed import TextEmbedding  # type: ignore\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Running on GPU:\", torch.cuda.get_device_name(0))\n",
    "    \n",
    "    # Preload necessary DLLs (optional, depending on your setup)\n",
    "    ort.preload_dlls()\n",
    "    \n",
    "    # Initialize the embedding model with CUDAExecutionProvider only\n",
    "    embedding_model_gpu = TextEmbedding(\n",
    "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "        device_ids='0',\n",
    "        providers=[\"CUDAExecutionProvider\"]\n",
    "    )\n",
    "    \n",
    "    # Verify the providers set for the model\n",
    "    print(\"Providers set for the model:\", embedding_model_gpu.model.model.get_providers())\n",
    "else:\n",
    "    print(\"CUDA is not available. Exiting.\")\n",
    "    raise SystemExit()\n",
    "\n",
    "# Test the embedding\n",
    "texts = [\"\"\"Enter\"\"\"]\n",
    "embeddings = list(embedding_model_gpu.embed(texts))\n",
    "\n",
    "# Print some sample embeddings\n",
    "print(\"Sample Embedding:\", embeddings[0][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "print(ort.get_available_providers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved optimum model to ../app/models/bge-base-en-v1.5_ONNX. Use it with `embed_model = OptimumEmbedding(folder_name='../app/models/bge-base-en-v1.5_ONNX')`.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface_optimum import OptimumEmbedding # type: ignore\n",
    "\n",
    "OptimumEmbedding.create_and_save_optimum_model(\"BAAI/bge-base-en-v1.5\", \"../app/models/bge-base-en-v1.5_ONNX\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
